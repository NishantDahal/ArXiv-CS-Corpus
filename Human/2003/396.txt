On the scaling of computational particle physics codes on cluster computers

Many appplications in computational science are sufficiently compute-intensive that they depend on the power of parallel computing for viability. For all but the "embarrassingly parallel" problems, the performance depends upon the level of granularity that can be achieved on the computer platform.
  Our computational particle physics applications require machines that can support a wide range of granularities, but in general, compute-intensive state-of-the-art projects will require finely grained distributions. Of the different types of machines available for the task, we consider cluster computers.
  The use of clusters of commodity computers in high performance computing has many advantages including the raw price/performance ratio and the flexibility of machine configuration and upgrade. Here we focus on what is usually considered the weak point of cluster technology; the scaling behaviour when faced with a numerically intensive parallel computation. To this end we examine the scaling of our own applications from numerical quantum field theory on a cluster and infer conclusions about the more general case.
