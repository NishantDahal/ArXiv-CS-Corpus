Rigid Body Localization Using Sensor Networks: Position and Orientation Estimation

In this paper, we propose a novel framework called rigid body localization for joint position and orientation estimation of a rigid body. We consider a setup in which a few sensors are mounted on a rigid body. The absolute position of the sensors on the rigid body, or the absolute position of the rigid body itself is not known. However, we know how the sensors are mounted on the rigid body, i.e., the sensor topology is known. Using range-only measurements between the sensors and a few anchors (nodes with known absolute positions), and without using any inertial measurements (e.g., accelerometers), we estimate the position and orientation of the rigid body. For this purpose, the absolute position of the sensors is expressed as an affine function of the Stiefel manifold. In other words, we represent the orientation as a rotation matrix, and absolute position as a translation vector. We propose a least-squares (LS), simplified unitarily constrained LS (SUC-LS), and optimal unitarily constrained least-squares (OUC-LS) estimator, where the latter is based on Newton's method. As a benchmark, we derive a unitarily constrained Cram√©r-Rao bound (UC-CRB). The known topology of the sensors can sometimes be perturbed during fabrication. To take these perturbations into account, a simplified unitarily constrained total-least-squares (SUC-TLS), and an optimal unitarily constrained total-least-squares (OUC-TLS) estimator are also proposed.
