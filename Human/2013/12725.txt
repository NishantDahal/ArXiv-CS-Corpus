Dominant block guided optimal cache size estimation to maximize IPC of embedded software

Embedded system software is highly constrained from performance, memory footprint, energy consumption and implementing cost view point. It is always desirable to obtain better Instructions per Cycle. Instruction cache has major contribution in improving IPC. Cache memories are realized on the same chip where the processor is running. This considerably increases the system cost as well. Hence, it is required to maintain a trade off between cache sizes and performance improvement offered. Determining the number of cache lines and size of cache line are important parameters for cache designing. The design space for cache is quite large. It is time taking to execute the given application with different cache sizes on an instruction set simulator to figure out the optimal cache size. In this paper, a technique is proposed to identify a number of cache lines and cache line size for the L1 instruction cache that will offer best or nearly best IPC. Cache size is derived, at a higher abstraction level, from basic block analysis in the Low Level Virtual Machine environment. The cache size estimated is cross validated by simulating the set of benchmark applications with different cache sizes in simple scalar simulator. The proposed method seems to be superior in terms of estimation accuracy and estimation time as compared to the existing methods for estimation of optimal cache size parameters like cache line size, number of cache lines.
