Delay performance in random-access grid networks

We examine the impact of torpid mixing and meta-stability issues on the delay performance in wireless random-access networks. Focusing on regular meshes as prototypical scenarios, we show that the mean delays in an $L\times L$ toric grid with normalized load $ρ$ are of the order $(\frac{1}{1-ρ})^L$. This superlinear delay scaling is to be contrasted with the usual linear growth of the order $\frac{1}{1-ρ}$ in conventional queueing networks. The intuitive explanation for the poor delay characteristics is that (i) high load requires a high activity factor, (ii) a high activity factor implies extremely slow transitions between dominant activity states, and (iii) slow transitions cause starvation and hence excessively long queues and delays. Our proof method combines both renewal and conductance arguments. A critical ingredient in quantifying the long transition times is the derivation of the communication height of the uniformized Markov chain associated with the activity process. We also discuss connections with Glauber dynamics, conductance and mixing times. Our proof framework can be applied to other topologies as well, and is also relevant for the hard-core model in statistical physics and the sampling from independent sets using single-site update Markov chains.
