Efficient Parallel Computation of the Estimated Covariance Matrix

Computation of a signal's estimated covariance matrix is an important building block in signal processing, e.g., for spectral estimation. Each matrix element is a sum of products of elements in the input matrix taken over a sliding window. Any given product contributes to multiple output elements, thereby complicating parallelization. We present a novel algorithm that attains very high parallelism without repeating multiplications or requiring inter-core synchronization. Key to this is the assignment to each core of distinct diagonal segments of the output matrix, selected such that no multiplications need to be repeated yet only one core writes to any given output-matrix element, and exploitation of a shared memory (including L1 cache) that obviates the need for a corresponding awkward partitioning of the memory among cores. Implementation on Plurality's HyperCore shared-memory many-core architecture demonstrates linear speedup of up to 64 cores and speedups of ~85X for 128 cores. On an x86 system we demonstrate that the new algorithm has consider parallel speedups but also show that a sequential implementation of the new algorithm outperforms the parallel implementation of the baseline approach. On a quad-core x86 system, the new algorithm is 20X faster than sequential baseline and 5X than parallel implementation of the baseline.
