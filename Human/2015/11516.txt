Learning Mobile Robot Based on Adaptive Controlled Markov Chains

Herein we suggest a mobile robot-training algorithm that is based on the preference approximation of the decision taker who controls the robot, which in its turn is managed by the Markov chain. Setup of the model parameters is made on the basis of the data referring to the situations and decisions involving the decision taker. The model that adapts to the decision taker's preferences can be set up either a priori, during the process of the robot's normal operation, or during specially planned testing sessions. Basing on the simulation modelling data of the robot's operation process and on the decision taker's robot control we have set up the model parameters thus illustrating both working capacity of all algorithm components and adaptation effectiveness.
