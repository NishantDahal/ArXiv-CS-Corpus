Making the Most of Your Samples

We study the problem of setting a price for a potential buyer with a valuation drawn from an unknown distribution $D$. The seller has "data"' about $D$ in the form of $m \ge 1$ i.i.d. samples, and the algorithmic challenge is to use these samples to obtain expected revenue as close as possible to what could be achieved with advance knowledge of $D$.
  Our first set of results quantifies the number of samples $m$ that are necessary and sufficient to obtain a $(1-ε)$-approximation. For example, for an unknown distribution that satisfies the monotone hazard rate (MHR) condition, we prove that $\tildeΘ(ε^{-3/2})$ samples are necessary and sufficient. Remarkably, this is fewer samples than is necessary to accurately estimate the expected revenue obtained by even a single reserve price. We also prove essentially tight sample complexity bounds for regular distributions, bounded-support distributions, and a wide class of irregular distributions. Our lower bound approach borrows tools from differential privacy and information theory, and we believe it could find further applications in auction theory.
  Our second set of results considers the single-sample case. For regular distributions, we prove that no pricing strategy is better than $\tfrac{1}{2}$-approximate, and this is optimal by the Bulow-Klemperer theorem. For MHR distributions, we show how to do better: we give a simple pricing strategy that guarantees expected revenue at least $0.589$ times the maximum possible. We also prove that no pricing strategy achieves an approximation guarantee better than $\frac{e}{4} \approx .68$.
