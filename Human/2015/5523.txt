GPGPU Based Parallelized Client-Server Framework for Providing High Performance Computation Support

Parallel data processing has become indispensable for processing applications involving huge data sets. This brings into focus the Graphics Processing Units (GPUs) which emphasize on many-core computing. With the advent of General Purpose GPUs (GPGPU), applications not directly associated with graphics operations can also harness the computation capabilities of GPUs. Hence, it would be beneficial if the computing capabilities of a given GPGPU could be task optimized and made available. This paper describes a client-server framework in which users can choose a processing task and submit large data-sets for processing to a remote GPGPU and receive the results back, using well defined interfaces. The framework provides extensibility in terms of the number and type of tasks that the client can choose or submit for processing at the remote GPGPU server machine, with complete transparency to the underlying hardware and operating systems. Parallelization of user-submitted tasks on the GPGPU has been achieved using NVIDIA Compute Unified Device Architecture (CUDA).
