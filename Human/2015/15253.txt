Context Driven Label Fusion for segmentation of Subcutaneous and Visceral Fat in CT Volumes

Quantification of adipose tissue (fat) from computed tomography (CT) scans is conducted mostly through manual or semi-automated image segmentation algorithms with limited efficacy. In this work, we propose a completely unsupervised and automatic method to identify adipose tissue, and then separate Subcutaneous Adipose Tissue (SAT) from Visceral Adipose Tissue (VAT) at the abdominal region. We offer a three-phase pipeline consisting of (1) Initial boundary estimation using gradient points, (2) boundary refinement using Geometric Median Absolute Deviation and Appearance based Local Outlier Scores (3) Context driven label fusion using Conditional Random Fields (CRF) to obtain the final boundary between SAT and VAT. We evaluate the proposed method on 151 abdominal CT scans and obtain state-of-the-art 94% and 91% dice similarity scores for SAT and VAT segmentation, as well as significant reduction in fat quantification error measure.
