Online Distributed ADMM on Networks

This paper examines online distributed Alternating Direction Method of Multipliers (ADMM). The goal is to distributively optimize a global objective function over a network of decision makers under linear constraints. The global objective function is composed of convex cost functions associated with each agent. The local cost functions, on the other hand, are assumed to have been decomposed into two distinct convex functions, one of which is revealed to the decision makers over time and one known a priori. In addition, the agents must achieve consensus on the global variable that relates to the private local variables via linear constraints. In this work, we extend online ADMM to a distributed setting based on dual-averaging and distributed gradient descent. We then propose a performance metric for such online distributed algorithms and explore the performance of the sequence of decisions generated by the algorithm as compared with the best fixed decision in hindsight. This performance metric is called the social regret. A sub-linear upper bound on the social regret of the proposed algorithm is then obtained that underscores the role of the underlying network topology and certain condition measures associated with the linear constraints. The online distributed ADMM algorithm is then applied to a formation acquisition problem demonstrating the application of the proposed setup in distributed robotics.
