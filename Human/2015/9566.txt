Characterization and Control of Diffusion Processes in Multi-Agent Networks

Diffusion processes are instrumental to describe the movement of a continuous quantity in a generic network of interacting agents. Here, we present a probabilistic framework for diffusion in networks and propose to classify agent interactions according to two protocols where the total network quantity is conserved or variable. For both protocols, our focus is on asymmetric interactions between agents involving directed graphs. Specifically, we define how the dynamics of conservative and non-conservative networks relate to the weighted in-degree Laplacian and the weighted out-degree Laplacian. Our framework allows the addition and subtraction of the considered quantity to and from a set of nodes. This enables the modeling of stubborn agents with time-invariant quantities, and the process of dynamic learning. We highlight several stability and convergence characteristics of our framework, and define the conditions under which asymptotic convergence is guaranteed when the network topology is variable. In addition, we indicate how our framework accommodates external network control and targeted network design. We show how network diffusion can be externally manipulated by applying time-varying input functions at individual nodes. Desirable network structures can also be constructed by adjusting the dominant diffusion modes. To this purpose, we propose a Markov decision process that learns these network adjustments through a reinforcement learning algorithm, suitable for large networks. The presented network control and design schemes enable flow modifications that allow the alteration of the dynamic and stationary behavior of the network in conservative and non-conservative networks.
