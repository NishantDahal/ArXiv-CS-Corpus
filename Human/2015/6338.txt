Coordination in State-Dependent Distributed Networks: The Two-Agent Case

This paper addresses a coordination problem between two agents (Agents $1$ and $2$) in the presence of a noisy communication channel which depends on an external system state $\{x_{0,t}\}$. The channel takes as inputs both agents' actions, $\{x_{1,t}\}$ and $\{x_{2,t}\}$ and produces outputs that are observed strictly causally at Agent $2$ but not at Agent $1$. The system state is available either causally or non-causally at Agent $1$ but unknown at Agent $2$. Necessary and sufficient conditions on a joint distribution $\bar{Q}(x_0,x_1,x_2)$ to be implementable asymptotically (i.e, when the number of taken actions grows large) are provided for both causal and non-causal state information at Agent $1$.
  Since the coordination degree between the agents' actions, $x_{1,t}$ and $x_{2,t}$, and the system state $x_{0,t}$ is measured in terms of an average payoff function, feasible payoffs are fully characterized by implementable joint distributions. In this sense, our results allow us to derive the performance of optimal power control policies on an interference channel and to assess the gain provided by non-causal knowledge of the system state at Agent $1$.
  The derived proofs readily yield new results also for the problem of state-amplification under a causality constraint at the decoder.
