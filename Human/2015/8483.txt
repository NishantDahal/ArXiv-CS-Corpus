A New and More General Capacity Theorem for the Gaussian Channel with Two-sided Input-Noise Dependent State Information

In this paper, a new and general version of Gaussian channel in presence of two-sided state information correlated to the channel input and noise is considered. Determining a general achievable rate for the channel and obtaining the capacity in a non-limiting case, we try to analyze and solve the Gaussian version of the Cover-Chiang theorem -as an open problem- mathematically and information-theoretically. Our capacity theorem, while including all previous theorems as its special cases, explains situations that can not be analyzed by them; for example, the effect of the correlation between the side information and the channel input on the capacity of the channel that can not be analyzed with Costa's "writing on dirty paper" theorem. Meanwhile, we try to introduce our new idea, i.e., describing the concept of "cognition" of a communicating object (transmitter, receiver, relay and so on) on some variable (channel noise, interference and so on) with the information-theoretic concept of "side information" correlated to that variable and known by the object. According to our theorem, the channel capacity is an increasing function of the mutual information of the side information and the channel noise. Therefore our channel and its capacity theorem exemplify the "cognition" of the transmitter and receiver on the channel noise based on the new description. Our capacity theorem has interesting interpretations originated from this new idea.
