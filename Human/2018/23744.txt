A convex program for bilinear inversion of sparse vectors

We consider the bilinear inverse problem of recovering two vectors, $\boldsymbol{x}\in\mathbb{R}^L$ and $\boldsymbol{w}\in\mathbb{R}^L$, from their entrywise product. We consider the case where $\boldsymbol{x}$ and $\boldsymbol{w}$ have known signs and are sparse with respect to known dictionaries of size $K$ and $N$, respectively. Here, $K$ and $N$ may be larger than, smaller than, or equal to $L$. We introduce $\ell_1$-BranchHull, which is a convex program posed in the natural parameter space and does not require an approximate solution or initialization in order to be stated or solved. We study the case where $\boldsymbol{x}$ and $\boldsymbol{w}$ are $S_1$- and $S_2$-sparse with respect to a random dictionary and present a recovery guarantee that only depends on the number of measurements as $L\geqÎ©(S_1+S_2)\log^{2}(K+N)$. Numerical experiments verify that the scaling constant in the theorem is not too large. One application of this problem is the sweep distortion removal task in dielectric imaging, where one of the signals is a nonnegative reflectivity, and the other signal lives in a known subspace, for example that given by dominant wavelet coefficients. We also introduce a variants of $\ell_1$-BranchHull for the purposes of tolerating noise and outliers, and for the purpose of recovering piecewise constant signals. We provide an ADMM implementation of these variants and show they can extract piecewise constant behavior from real images.
