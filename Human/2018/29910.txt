An Analytical Approach to Improving Time Warping on Multidimensional Time Series

Dynamic time warping ($\texttt{DTW}$) is one of the most used distance functions to compare time series, e.$\,$g. in nearest neighbor classifiers. Yet, fast state of the art algorithms only compare 1-dimensional time series efficiently. One of these state of the art algorithms uses a lower bound ($\texttt{LB}_\texttt{Keogh}$) introduced by E. Keogh to prune $\texttt{DTW}$ computations. We introduce $\texttt{LB}_\texttt{Box}$ as a canonical extension to $\texttt{LB}_\texttt{Keogh}$ on multi-dimensional time series. We evaluate its performance conceptually and experimentally and show that an alternative to $\texttt{LB}_\texttt{Box}$ is necessary for multi-dimensional time series. We also propose a new algorithm for the dog-keeper distance ($\texttt{DK}$) which is an alternative distance function to $\texttt{DTW}$ and show that it outperforms $\texttt{DTW}$ with $\texttt{LB}_\texttt{Box}$ by more than one order of magnitude on multi-dimensional time series.
