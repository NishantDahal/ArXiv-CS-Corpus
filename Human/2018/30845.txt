Achieving Differential Privacy using Methods from Calculus

We introduce derivative sensitivity, an analogue to local sensitivity for continuous functions. We use this notion in an analysis that determines the amount of noise to be added to the result of a database query in order to obtain a certain level of differential privacy, and demonstrate that derivative sensitivity allows us to employ powerful mechanisms from calculus to perform the analysis for a variety of queries. We have implemented the analyzer and evaluated its efficiency and precision.
  We also show the flexibility of derivative sensitivity in specifying the quantitative privacy notion of the database, as desired by the data owner. Instead of only using the `number of changed rows' metric, our metrics can depend on the locations and amounts of changes in a much more nuanced manner. This will help to make sure that the distance is not larger than the data owner desires (which would undermine privacy), thereby encouraging the adoption of differentially private data analysis mechanisms.
