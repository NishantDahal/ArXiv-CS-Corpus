Brief Notes on Hard Takeoff, Value Alignment, and Coherent Extrapolated Volition

I make some basic observations about hard takeoff, value alignment, and coherent extrapolated volition, concepts which have been central in analyses of superintelligent AI systems.
