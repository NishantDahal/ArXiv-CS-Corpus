Entropic CLT and phase transition in high-dimensional Wishart matrices

We consider high dimensional Wishart matrices $\mathbb{X} \mathbb{X}^{\top}$ where the entries of $\mathbb{X} \in {\mathbb{R}^{n \times d}}$ are i.i.d. from a log-concave distribution. We prove an information theoretic phase transition: such matrices are close in total variation distance to the corresponding Gaussian ensemble if and only if $d$ is much larger than $n^3$. Our proof is entropy-based, making use of the chain rule for relative entropy along with the recursive structure in the definition of the Wishart ensemble. The proof crucially relies on the well known relation between Fisher information and entropy, a variational representation for Fisher information, concentration bounds for the spectral norm of a random matrix, and certain small ball probability estimates for log-concave measures.
