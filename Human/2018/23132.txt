Edge Cloud System Evaluation

Real-time applications in the next generation networks often rely upon offloading the computational task to a \textit{nearby} server to achieve ultra-low latency. Augmented reality applications for instance have strict latency requirements which can be fulfilled by an interplay between cloud and edge servers. In this work, we study the impact of load on a hybrid edge cloud system. The resource distribution between central cloud and edge affects the capacity of the network. Optimizing delay and capacity constraints of this hybrid network is similar to maximum cardinal bin packing problem which is NP-hard. We design a simulation framework using a city-scale access point dataset to propose an enhanced capacity edge cloud network while answering following questions: (a) how much load an edge cloud network can support without affecting the performance of an application, (b) how is application delay-constraint limit affects the capacity of the network, (c) what is the impact of load and resource distribution on goodput, (d) under what circumstances, cloud can perform better than edge network and (e) what is the impact of inter-edge networking bandwidth on the system capacity. An evaluation system and model is developed to analyze the tradeoffs of different edge cloud deployments and results are shown to support the claims.
