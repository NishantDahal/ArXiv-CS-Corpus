On Distributed Nonlinear Signal Analytics : Bandwidth and Approximation Error Tradeoffs

Analytics will be a part of the upcoming smart city and Internet of Things (IoT). The focus of this work is approximate distributed signal analytics. It is envisaged that distributed IoT devices will record signals, which may be of interest to the IoT cloud. Communication of these signals from IoT devices to the IoT cloud will require (lowpass) approximations. Linear signal approximations are well known in the literature. It will be outlined that in many IoT analytics problems, it is desirable that the approximated signals (or their analytics) should always over-predict the exact signals (or their analytics). This distributed nonlinear approximation problem has not been studied before. An algorithm to perform distributed over-predictive signal analytics in the IoT cloud, based on signal approximations by IoT devices, is proposed. The fundamental tradeoff between the signal approximation bandwidth used by IoT devices and the approximation error in signal analytics at the IoT cloud is quantified for the class of differentiable signals. Simulation results are also presented.
