Stochastic 2-D Motion Planning with a POMDP Framework

Motion planning is challenging when it comes to the case of imperfect state information. Decision should be made based on belief state which evolves according to the noise from the system dynamics and sensor measurement. In this paper, we propose the QV-Tree Search algorithm which combines the state-of-art offline and online approximation methods for POMDP. Instead of full node expansions in the tree search, only probable future observations are considered through forward sampling. This modification helps reduce online computation time and allows for GPU acceleration. We show using repre- sentative examples that the proposed QV-Tree Search is able to actively localize the robot in order to reach the goal location with high probability. The results of the proposed method is also compared with the A* and MDP algorithms, neither of which handles state uncertainty directly. The comparison shows that QV-Tree Search is able to drive the robot to the goal with higher success rate and fewer steps.
