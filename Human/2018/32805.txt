Matrix Exponential Learning Schemes with Low Informational Exchange

We consider a distributed resource allocation problem in networks where each transmitter-receiver pair aims at maximizing its local utility function by adjusting its action matrix, which belongs to a given feasible set. This problem has been addressed recently by applying a matrix exponential learning (MXL) algorithm which has a very appealing convergence rate. In this learning algorithm, however, each transmitter must know an estimate of the gradient matrix of the local utility. The knowledge of the gradient matrix at the transmitters incurs a high signaling overhead especially that the matrix size increases with the dimension of the action matrix. In this paper, we therefore investigate two strategies in order to decrease the informational exchange per iteration of the algorithm. In the first strategy, each receiver sends at each iteration part of the elements of the gradient matrix with respect to a certain probability. In the second strategy, each receiver feeds back sporadically the whole gradient matrix. We focus on the analysis of the convergence of the MXL algorithm to optimum under these two strategies. We prove that the algorithm can still converge to optimum almost surely. Upper bounds of the average convergence rate are also derived in both situations with general step-size setting, from which we can clearly see the impact of the incompleteness of the feedback information. The proposed algorithms are applied to solve the energy efficiency maximization problem in a multicarrier multi-user MIMO network. Simulation results further corroborate our claim.
