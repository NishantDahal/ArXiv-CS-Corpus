Decoupling Semantic Context and Color Correlation with multi-class cross branch regularization

This paper presents a novel design methodology for architecting a light-weight and faster DNN architecture for vision applications. The effectiveness of the architecture is demonstrated on Color-Constancy use case an inherent block in camera and imaging pipelines. Specifically, we present a multi-branch architecture that disassembles the contextual features and color properties from an image, and later combines them to predict a global property (e.g. Global Illumination). We also propose an implicit regularization technique by designing cross-branch regularization block that enables the network to retain high generalization accuracy. With a conservative use of best computational operators, the proposed architecture achieves state-of-the-art accuracy with 30X lesser model parameters and 70X faster inference time for color constancy. It is also shown that the proposed architecture is generic and achieves similar efficiency in other vision applications such as Low-Light photography.
