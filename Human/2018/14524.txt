Equilibrium and Learning in Queues with Advance Reservations

Consider a multi-class preemptive-resume $M/D/1$ queueing system that supports advance reservations (AR). In this system, strategic customers must decide whether to reserve a server in advance (thereby gaining higher priority) or avoid AR. Reserving a server in advance bears a cost. In this paper, we conduct a game-theoretic analysis of this system, characterizing the equilibrium strategies. Specifically, we show that the game has two types of equilibria. In one type, none of the customers makes reservation. In the other type, only customers that realize early enough that they will need service make reservations. We show that the types and number of equilibria depend on the parameters of the queue and on the reservation cost. Specifically, we prove that the equilibrium is unique if the server utilization is below 1/2. Otherwise, there may be multiple equilibria depending on the reservation cost. Next, we assume that the reservation cost is a fee set by the provider. In that case, we show that the revenue maximizing fee leads to a unique equilibrium if the utilization is below 2/3, but multiple equilibria if the utilization exceeds 2/3. Finally, we study a dynamic version of the game, where users learn and adapt their strategies based on observations of past actions or strategies of other users. Depending on the type of learning (i.e., action learning vs.\ strategy learning), we show that the game converges to an equilibrium in some cases, while it cycles in other cases.
