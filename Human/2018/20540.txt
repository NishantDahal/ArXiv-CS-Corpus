A Joint Motion Model for Human-Like Robot-Human Handover

In future, robots will be present in everyday life. The development of these supporting robots is a challenge. A fundamental task for assistance robots is to pick up and hand over objects to humans. By interacting with users, soft factors such as predictability, safety and reliability become important factors for development. Previous works show that collaboration with robots is more acceptable when robots behave and move human-like. In this paper, we present a motion model based on the motion profiles of individual joints. These motion profiles are based on observations and measurements of joint movements in human-human handover. We implemented this joint motion model (JMM) on a humanoid and a non-humanoidal industrial robot to show the movements to subjects. Particular attention was paid to the recognizability and human similarity of the movements. The results show that people are able to recognize human-like movements and perceive the movements of the JMM as more human-like compared to a traditional model. Furthermore, it turns out that the differences between a linear joint space trajectory and JMM are more noticeable in an industrial robot than in a humanoid robot.
