Real World Evaluation of Approaches to Research Paper Recommendation

In this work, we have identified the need for choosing baseline approaches for research-paper recommendation systems. Following a literature survey of all research paper recommendation approaches described over the last four years, we framed criteria that makes for a well-rounded set of baselines. These are implemented on Mr. DLib a literature recommendation platform. User click data was collected as part of an ongoing experiment in collaboration with our partner Gesis. We reported the results from our evaluation for the experiments. We will be able to draw clearer conclusions as time passes. We find that a term based similarity search performs better than keyword based approaches. These results are a good starting point in finding performance improvements for related document searches.
