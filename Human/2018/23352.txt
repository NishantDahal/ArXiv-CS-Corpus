Robust Sensor Fusion for Robot Attitude Estimation

Knowledge of how a body is oriented relative to the world is frequently invaluable information in the field of robotics. An attitude estimator that fuses 3-axis gyroscope, accelerometer and magnetometer data into a quaternion orientation estimate is presented in this paper. The concept of fused yaw, used by the estimator, is also introduced. The estimator, a nonlinear complementary filter at heart, is designed to be uniformly robust and stable---independent of the absolute orientation of the body---and has been implemented and released as a cross-platform open source C++ library. Extensions to the estimator, such as quick learning and the ability to deal dynamically with cases of reduced sensory information, are also presented.
