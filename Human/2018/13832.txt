A Pessimistic Approximation for the Fisher Information Measure

The problem of determining the intrinsic quality of a signal processing system with respect to the inference of an unknown deterministic parameter $θ$ is considered. While the Fisher information measure $F(θ)$ forms a classical tool for such a problem, direct computation of the information measure can become difficult in various situations. For the estimation theoretic performance analysis of nonlinear measurement systems, the form of the likelihood function can make the calculation of the information measure $F(θ)$ challenging. In situations where no closed-form expression of the statistical system model is available, the analytical derivation of $F(θ)$ is not possible at all. Based on the Cauchy-Schwarz inequality, we derive an alternative information measure $S(θ)$. It provides a lower bound on the Fisher information $F(θ)$ and has the property of being evaluated with the mean, the variance, the skewness and the kurtosis of the system model at hand. These entities usually exhibit good mathematical tractability or can be determined at low-complexity by real-world measurements in a calibrated setup. With various examples, we show that $S(θ)$ provides a good conservative approximation for $F(θ)$ and outline different estimation theoretic problems where the presented information bound turns out to be useful.
