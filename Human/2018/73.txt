Cost- and Energy-Aware Multi-Flow Mobile Data Offloading Using Markov Decision Process

With the rapid increase in demand for mobile data, mobile network operators are trying to expand wireless network capacity by deploying wireless local area network (LAN) hotspots on which they can offload their mobile traffic. However, these network-centric methods usually do not fulfill the interests of mobile users (MUs). Taking into consideration many issues, MUs should be able to decide whether to offload their traffic to a complementary wireless LAN. Our previous work studied single-flow wireless LAN offloading from a MU's perspective by considering delay-tolerance of traffic, monetary cost and energy consumption. In this paper, we study the multi-flow mobile data offloading problem from a MU's perspective in which a MU has multiple applications to download data simultaneously from remote servers, and different applications' data have different deadlines. We formulate the wireless LAN offloading problem as a finite-horizon discrete-time Markov decision process (MDP) and establish an optimal policy by a dynamic programming based algorithm. Since the time complexity of the dynamic programming based offloading algorithm is still high, we propose a low time complexity heuristic offloading algorithm with performance sacrifice. Extensive simulations are conducted to validate our proposed offloading algorithms.
