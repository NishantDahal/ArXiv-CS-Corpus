Why Noise and Dispersion may Seriously Hamper Nonlinear Frequency-Division Multiplexing

The performance of optical fiber systems based on nonlinear frequency-division multiplexing (NFDM) or on more conventional transmission techniques is compared through numerical simulations. Some critical issues affecting NFDM systems-namely, the strict requirements needed to avoid burst interaction due to signal dispersion and the unfavorable dependence of performance on burst length-are investigated, highlighting their potentially disruptive effect in terms of spectral efficiency. Two digital processing techniques are finally proposed to halve the guard time between NFDM symbol bursts and reduce the size of the processing window at the receiver, increasing spectral efficiency and reducing computational complexity.
