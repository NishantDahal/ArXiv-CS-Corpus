Minimax Optimal Estimators for Additive Scalar Functionals of Discrete Distributions

In this paper, we consider estimators for an additive functional of $φ$, which is defined as $θ(P;φ)=\sum_{i=1}^kφ(p_i)$, from $n$ i.i.d. random samples drawn from a discrete distribution $P=(p_1,...,p_k)$ with alphabet size $k$. We propose a minimax optimal estimator for the estimation problem of the additive functional. We reveal that the minimax optimal rate is characterized by the divergence speed of the fourth derivative of $φ$ if the divergence speed is high. As a result, we show there is no consistent estimator if the divergence speed of the fourth derivative of $φ$ is larger than $p^{-4}$. Furthermore, if the divergence speed of the fourth derivative of $φ$ is $p^{4-α}$ for $α\in (0,1)$, the minimax optimal rate is obtained within a universal multiplicative constant as $\frac{k^2}{(n\ln n)^{2α}} + \frac{k^{2-2α}}{n}$.
