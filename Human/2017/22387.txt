$k$-NN Estimation of Directed Information

This report studies data-driven estimation of the directed information (DI) measure between two{em discrete-time and continuous-amplitude} random process, based on the $k$-nearest-neighbors ($k$-NN) estimation framework. Detailed derivations of two $k$-NN estimators are provided. The two estimators differ in the metric based on which the nearest-neighbors are found. To facilitate the estimation of the DI measure, it is assumed that the observed sequences are (jointly) Markovian of order $m$. As $m$ is generally not known, a data-driven method (that is also based on the $k$-NN principle) for estimating $m$ from the observed sequences is presented. An exhaustive numerical study shows that the discussed $k$-NN estimators perform well even for relatively small number of samples (few thousands). Moreover, it is shown that the discussed estimators are capable of accurately detecting linear as well as non-linear causal interactions.
