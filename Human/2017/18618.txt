Optimal Detection for Diffusion-Based Molecular Timing Channels

This work studies optimal detection for communication over diffusion-based molecular timing (DBMT) channels. The transmitter simultaneously releases multiple information particles, where the information is encoded in the time of release. The receiver decodes the transmitted information based on the random time of arrival of the information particles, which is modeled as an additive noise channel. For a DBMT channel without flow, this noise follows the Lévy distribution. Under this channel model, the maximum-likelihood (ML) detector is derived and shown to have high computational complexity. It is also shown that under ML detection, releasing multiple particles improves performance, while for any additive channel with $α$-stable noise where $α<1$ (such as the DBMT channel), under linear processing at the receiver, releasing multiple particles degrades performance relative to releasing a single particle. Hence, a new low-complexity detector, which is based on the first arrival (FA) among all the transmitted particles, is proposed. It is shown that for a small number of released particles, the performance of the FA detector is very close to that of the ML detector. On the other hand, error exponent analysis shows that the performance of the two detectors differ when the number of released particles is large.
