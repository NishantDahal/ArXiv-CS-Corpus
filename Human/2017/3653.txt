Random Forest Resource Allocation for 5G Systems: Performance and Robustness Study

Next generation cellular networks will have to leverage large cell densifications to accomplish the ambitious goals for aggregate multi-user sum rates, for which CRAN architecture is a favored network design. This shifts the attention back to applicable resource allocation (RA), which need to be applicable for very short radio frames, large and dense sets of radio heads, and large user populations in the coordination area. So far, mainly CSI-based RA schemes have been proposed for this task. However, they have considerable complexity and also incur a significant CSI acquisition overhead on the system. In this paper, we study an alternative approach which promises lower complexity with also a lower overhead. We propose to base the RA in multi-antenna CRAN systems on the position information of user terminals only. We use Random Forests as supervised machine learning approach to determine the multi-user RAs. This likely leads to lower overhead costs, as the acquisition of position information requires less radio resources in comparison to the acquisition of instantaneous CSI. The results show the following findings: I) In general, learning-based RA schemes can achieve comparable spectral efficiency to CSI-based scheme; II) If taking the system overhead into account, learning-based RA scheme utilizing position information outperform legacy CSI-based scheme by up to 100%; III) Despite their dependency on the training data, Random Forests based RA scheme is robust against position inaccuracies and changes in the propagation scenario; IV) The most important factor influencing the performance of learning-based RA scheme is the antenna orientation, for which we present three approaches that restore most of the original performance results. To the best of our knowledge, these insights are new and indicate a novel as well as promising approach to master the complexity in future cellular networks.
