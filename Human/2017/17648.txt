Learning a Predictive Model for Music Using PULSE

Predictive models for music are studied by researchers of algorithmic composition, the cognitive sciences and machine learning. They serve as base models for composition, can simulate human prediction and provide a multidisciplinary application domain for learning algorithms. A particularly well established and constantly advanced subtask is the prediction of monophonic melodies. As melodies typically involve non-Markovian dependencies their prediction requires a capable learning algorithm. In this thesis, I apply the recent feature discovery and learning method PULSE to the realm of symbolic music modeling. PULSE is comprised of a feature generating operation and L1-regularized optimization. These are used to iteratively expand and cull the feature set, effectively exploring feature spaces that are too large for common feature selection approaches. I design a general Python framework for PULSE, propose task-optimized feature generating operations and various music-theoretically motivated features that are evaluated on a standard corpus of monophonic folk and chorale melodies. The proposed method significantly outperforms comparable state-of-the-art models. I further discuss the free parameters of the learning algorithm and analyze the feature composition of the learned models. The models learned by PULSE afford an easy inspection and are musicologically interpreted for the first time.
