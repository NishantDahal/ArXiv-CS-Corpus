Learning Belief Network Structure From Data under Causal Insufficiency

Though a belief network (a representation of the joint probability distribution, see [3]) and a causal network (a representation of causal relationships [14]) are intended to mean different things, they are closely related. Both assume an underlying dag (directed acyclic graph) structure of relations among variables and if Markov condition and faithfulness condition [15] are met, then a causal network is in fact a belief network. The difference comes to appearance when we recover belief network and causal network structure from data.
  A causal network structure may be impossible to recover completely from data as not all directions of causal links may be uniquely determined [15]. Fortunately, if we deal with causally sufficient sets of variables (that is whenever significant influence variables are not omitted from observation), then there exists the possibility to identify the family of belief networks a causal network belongs to [16]. Regrettably, to our knowledge, a similar result is not directly known for causally insufficient sets of variables. Spirtes, Glymour and Scheines developed a CI algorithm to handle this situation, but it leaves some important questions open.
  The big open question is whether or not the bidirectional edges (that is indications of a common cause) are the only ones necessary to develop a belief network out of the product of CI, or must there be some other hidden variables added (e.g. by guessing). This paper is devoted to settling this question.
