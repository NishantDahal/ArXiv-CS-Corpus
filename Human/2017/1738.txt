Combating the Cold Start User Problem in Model Based Collaborative Filtering

For tackling the well known cold-start user problem in model-based recommender systems, one approach is to recommend a few items to a cold-start user and use the feedback to learn a profile. The learned profile can then be used to make good recommendations to the cold user. In the absence of a good initial profile, the recommendations are like random probes, but if not chosen judiciously, both bad recommendations and too many recommendations may turn off a user. We formalize the cold-start user problem by asking what are the $b$ best items we should recommend to a cold-start user, in order to learn her profile most accurately, where $b$, a given budget, is typically a small number. We formalize the problem as an optimization problem and present multiple non-trivial results, including NP-hardness as well as hardness of approximation. We furthermore show that the objective function, i.e., the least square error of the learned profile w.r.t. the true user profile, is neither submodular nor supermodular, suggesting efficient approximations are unlikely to exist. Finally, we discuss several scalable heuristic approaches for identifying the $b$ best items to recommend to the user and experimentally evaluate their performance on 4 real datasets. Our experiments show that our proposed accelerated algorithms significantly outperform the prior art in runnning time, while achieving similar error in the learned user profile as well as in the rating predictions.
