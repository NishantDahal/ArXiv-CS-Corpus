A simple centrality index for scientific social recognition

We introduce a new centrality index for bipartite network of papers and authors that we call $K$-index. The $K$-index grows with the citation performance of the papers that cite a given researcher and can seen as a measure of scientific social recognition. Indeed, the $K$-index measures the number of hubs, defined in a self-consistent way in the bipartite network, that cites a given author. We show that the $K$-index can be computed by simple inspection of the Web of Science platform and presents several advantages over other centrality indexes, in particular Hirsch $h$-index. The $K$-index is robust to self-citations, is not limited by the total number of papers published by a researcher as occurs for the $h$-index and can distinguish in a consistent way researchers that have the same $h$-index but very different scientific social recognition. The $K$-index easily detects a known case of a researcher with inflated number of papers, citations and $h$-index due to scientific misconduct. Finally, we show that, in a sample of twenty-eight physics Nobel laureates and twenty-eight highly cited non-Nobel-laureate physicists, the $K$-index correlates better to the achievement of the prize than the number of papers, citations, citations per paper, citing articles or the $h$-index. Clustering researchers in a $K$ versus $h$ plot reveals interesting outliers that suggest that these two indexes can present complementary independent information.
