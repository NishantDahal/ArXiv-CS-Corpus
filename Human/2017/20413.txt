Sistema de Navegação Autônomo Baseado em Visão Computacional

Autonomous robots are used as the tool to solve many kinds of problems, such as environmental mapping and monitoring. Either for adverse conditions related to the human presence or even for the need to reduce costs, it is certain that many efforts have been made to develop robots with an increasingly high level of autonomy. They must be capable of locomotion through dynamic environments, without human operators or assistant systems' help. It is noted, thus, that the form of perception and modeling of the environment becomes significantly relevant to navigation. Among the main sensing methods are those based on vision. Through this, it is possible to create highly-detailed models about the environment, since many characteristics can be measured, such as texture, color, and illumination. However, the most accurate vision-based navigation techniques are computationally expensive to run on low-cost mobile platforms. Therefore, the goal of this work was to develop a low-cost robot, controlled by a Raspberry Pi, whose navigation system is based on vision. For this purpose, the strategy used consisted in identifying obstacles via optical flow pattern recognition. Through this signal, it is possible to infer the relative displacement between the robot and other elements in the environment. Its estimation was done using the Lucas-Kanade algorithm, which can be executed by the Raspberry Pi without harming its performance. Finally, an SVM based classifier was used to identify patterns of this signal associated with obstacles movement. The developed system was evaluated considering its execution over an optical flow pattern dataset extracted from a real navigation environment. In the end, it was verified that the processing frequency of the system was superior to the others. Furthermore, its accuracy and acquisition cost were, respectively, higher and lower than most of the cited works.
