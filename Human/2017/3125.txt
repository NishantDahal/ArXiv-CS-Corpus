A Reputation-Based Contract for Repeated Crowdsensing with Costly Verification

We study a setup in which a system operator hires a sensor to exert costly effort to collect accurate measurements of a value of interest over time. At each time, the sensor is asked to report his observation to the operator, and is compensated based on the accuracy of this observation. Since both the effort and observation are private information for the sensor, a naive payment scheme which compensates the sensor based only on his self-reported values will lead to both shirking and falsification of outcomes by the sensor. We consider the problem of designing an appropriate compensation scheme to incentivize the sensor to at once exert costly effort and truthfully reveal the resulting observation.
  To this end, we formulate the problem as a repeated game and propose a compensation scheme that employs stochastic verification by the operator coupled with a system of assigning reputation to the sensor. In particular, our proposed payment scheme compensates the sensor based on both the effort in the current period as well as the history of past behavior. We show that by using past behavior in determining present payments, the operator can both incentivize higher effort as well as more frequent truthtelling by the sensor and decrease the required verification frequency.
