Labeling and Retrieval of Emotionally-Annotated Images using WordNet

Repositories of images with semantic and emotion content descriptions are valuable tools in many areas such as Affective Computing and Human-Computer Interaction, but they are also important in the development of multimodal searchable online databases. Ever growing number of image documents available on the Internet continuously motivates research of better annotation models and more efficient retrieval methods which use mash-up of available data on semantics, scenes, objects, events, context and emotion. Formal knowledge representation of such high-level semantics requires rich, explicit, human but also machine-processable information. To achieve these goals we present an online ontology-based image annotation tool WNtags and demonstrate its usefulness in knowledge representation and image retrieval using the International Affective Picture System database. The WNtags uses WordNet as image tagging glossary but considers Suggested Upper Merged Ontology as the preferred upper labeling formalism. The retrieval is performed using node distance metrics to establish semantic relatedness between a query and the collaboratively weighted tags describing high-level image semantics, after which the result is ranked according to the derived importance. We also elaborate plans to improve the WNtags to create a collaborative Web-based multimedia repository for research in human emotion and attention.
