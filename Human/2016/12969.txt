Dynamic Programming for One-Sided Partially Observable Pursuit-Evasion Games

Pursuit-evasion scenarios appear widely in robotics, security domains, and many other real-world situations. We focus on two-player pursuit-evasion games with concurrent moves, infinite horizon, and discounted rewards. We assume that the players have a partial observability, however, the evader is given an advantage of knowing the current position of the units of the pursuer. This setting is particularly interesting for security domains where a robust strategy, designed to maximize the utility in the worst-case scenario, is often desirable. We provide, to the best of our knowledge, the first algorithm that provably converges to the value of a partially observable pursuit-evasion game with infinite horizon. Our algorithm extends well-known value iteration algorithm by exploiting that (1) the value functions of our game depend only on position of the pursuer and the belief he has about the current position of the evader, and (2) that these functions are piecewise linear and convex in the belief space.
