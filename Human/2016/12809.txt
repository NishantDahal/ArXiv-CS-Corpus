Deriving Conclusions From Non-Monotonic Cause-Effect Relations

We present an extension of Logic Programming (under stable models semantics) that, not only allows concluding whether a true atom is a cause of another atom, but also deriving new conclusions from these causal-effect relations. This is expressive enough to capture informal rules like "if some agent's actions $\mathcal{A}$ have been necessary to cause an event $E$ then conclude atom $caused(\mathcal{A},E)$," something that, to the best of our knowledge, had not been formalised in the literature. To this aim, we start from a first attempt that proposed extending the syntax of logic programs with so-called causal literals. These causal literals are expressions that can be used in rule bodies and allow inspecting the derivation of some atom $A$ in the program with respect to some query function $Ï†$. Depending on how these query functions are defined, we can model different types of causal relations such as sufficient, necessary or contributory causes, for instance. The initial approach was specifically focused on monotonic query functions. This was enough to cover sufficient cause-effect relations but, unfortunately, necessary and contributory are essentially non-monotonic. In this work, we define a semantics for non-monotonic causal literals showing that, not only extends the stable model semantics for normal logic programs, but also preserves many of its usual desirable properties for the extended syntax. Using this new semantics, we provide precise definitions of necessary and contributory causal relations and briefly explain their behaviour on a pair of typical examples from the Knowledge Representation literature. (Under consideration for publication in Theory and Practice of Logic Programming)
