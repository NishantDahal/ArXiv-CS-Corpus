Low Complexity Sparse Bayesian Learning Using Combined BP and MF with a Stretched Factor Graph

This paper concerns message passing based approaches to sparse Bayesian learning (SBL) with a linear model corrupted by additive white Gaussian noise with unknown variance. With the conventional factor graph, mean field (MF) message passing based algorithms have been proposed in the literature. In this work, instead of using the conventional factor graph, we modify the factor graph by adding some extra hard constraints (the graph looks like being `stretched'), which enables the use of combined belief propagation (BP) and MF message passing. We then propose a low complexity BP-MF SBL algorithm based on which an approximate BP-MF SBL algorithm is also developed to further reduce the complexity. Thanks to the use of BP, the BP-MF SBL algorithms show their merits compared with state-of-the-art MF SBL algorithms: they deliver even better performance with much lower complexity compared with the vector-form MF SBL algorithm and they significantly outperform the scalar-form MF SBL algorithm with similar complexity.
