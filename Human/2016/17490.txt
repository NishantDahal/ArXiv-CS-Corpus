Multi-sensor perceptual system for mobile robot and sensor fusion-based localization

This paper presents an Extended Kalman Filter (EKF) approach to localize a mobile robot with two quadrature encoders, a compass sensor, a laser range finder (LRF) and an omni-directional camera. The prediction step is performed by employing the kinematic model of the robot as well as estimating the input noise covariance matrix as being proportional to the wheel's angular speed. At the correction step, the measurements from all sensors including incremental pulses of the encoders, line segments of the LRF, robot orientation of the compass and deflection angular of the omni-directional camera are fused. Experiments in an indoor structured environment were implemented and the good localization results prove the effectiveness and applicability of the algorithm.
