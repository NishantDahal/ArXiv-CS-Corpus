A Human Computer Interaction Solution for Radiology Reporting: Evaluation of the Factors of Variation

The purpose of this research is to evaluate the human and technical factors required to create a human-computer interface (HCI) for a structured reporting solution based on eye-gaze and speech signals. Gaze and speech signals from radiologists acquired during simulated image interpretation and dictation sessions were analyzed to determine a) variation of temporal relationship between eye gaze and speech in a dictation environment, and b) variation in eye movements for a particular image interpretation task among radiologists. Knowledge of these factors provides information regarding the complexity of the image interpretation or dictation task, and provides information that can be used to design a HCI for use in diagnostic radiology. Our ultimate goal is to use these data to create an HCI to automate the generation of a particular type of structured radiology report. Our data indicate that the a) temporal relationships between eye gaze and speech and b) scan paths substantially vary among radiologists, thus implying that an HCI system based on eye gaze and speech for automating the capture of data for structured reporting processes should be customized for each user. The image resolution and layout, image content, and order of targets during an image interpretation session are not relevant factors to consider when designing an HCI. Our findings can be applied to the design of other HCI solutions for radiological applications that involve visual inspection and verbal descriptions of image findings.
