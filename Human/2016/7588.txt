Sharp Bounds Between Two Rényi Entropies of Distinct Positive Orders

Many axiomatic definitions of entropy, such as the Rényi entropy, of a random variable are closely related to the $\ell_α$-norm of its probability distribution. This study considers probability distributions on finite sets, and examines the sharp bounds of the $\ell_β$-norm with a fixed $\ell_α$-norm, $α\neq β$, for $n$-dimensional probability vectors with an integer $n \ge 2$. From the results, we derive the sharp bounds of the Rényi entropy of positive order $β$ with a fixed Rényi entropy of another positive order $α$. As applications, we investigate sharp bounds of Ariomoto's mutual information of order $α$ and Gallager's random coding exponents for uniformly focusing channels under the uniform input distribution.
