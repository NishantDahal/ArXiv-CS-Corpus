Understanding and coping with extremism in an online collaborative environment

The Internet has provided us with great opportunities for large scale collaborative public good projects. Wikipedia is a predominant example of such projects where conflicts emerge and get resolved through bottom-up mechanisms leading to the emergence of the largest encyclopedia in human history. Disaccord arises whenever editors with different opinions try to produce an article reflecting a consensual view. The debates are mainly heated by editors with extremist views. Using a model of common value production, we show that the consensus can only be reached if extremist groups can actively take part in the discussion and if their views are also represented in the common outcome, at least temporarily. We show that banning problematic editors mostly hinders the consensus as it delays discussion and thus the whole consensus building process. To validate the model, relevant quantities are measured both in simulations and Wikipedia which show satisfactory agreement. We also consider the role of direct communication between editors both in the model and in Wikipedia data (by analysing the Wikipedia {\it talk} pages). While the model suggests that in certain conditions there is an optimal rate of "talking" vs "editing", it correctly predicts that in the current settings of Wikipedia, more activity in talk pages is associated with more controversy.
