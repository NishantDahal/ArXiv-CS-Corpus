Partial Diffusion Recursive Least-Squares for Distributed Estimation under Noisy Links Condition

Partial diffusion-based recursive least squares (PDRLS) is an effective method for reducing computational load and power consumption in adaptive network implementation. In this method, each node shares a part of its intermediate estimate vector with its neighbors at each iteration. PDRLS algorithm reduces the internode communications relative to the full-diffusion RLS algorithm. This selection of estimate entries becomes more appealing when the information fuse over noisy links. In this paper, we study the steady-state performance of PDRLS algorithm in presence of noisy links and investigate its convergence in both mean and mean-square senses. We also derive a theoretical expression for its steady-state meansquare deviation (MSD). The simulation results illustrate that the stability conditions for PDRLS under noisy links are not sufficient to guarantee its convergence. Strictly speaking, considering nonideal links condition adds a new complexity to the estimation problem for which the PDRLS algorithm becomes unstable and do not converge for any value of the forgetting factor.
