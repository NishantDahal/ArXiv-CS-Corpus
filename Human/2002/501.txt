Reconciling MPEG-7 and MPEG-21 Semantics through a Common Event-Aware Metadata Model

The "event" concept appears repeatedly when developing metadata models for the description and management of multimedia content. During the typical life cycle of multimedia content, events occur at many different levels - from the events which happen during content creation (directing, acting, camera panning and zooming) to the events which happen to the physical form (acquisition, relocation, damage of film or video) to the digital conversion, reformatting, editing and repackaging events, to the events which are depicted in the actual content (political, news, sporting) to the usage, ownership and copyright agreement events and even the metadata attribution events. Support is required within both MPEG-7 and MPEG-21 for the clear and unambiguous description of all of these event types which may occur at widely different levels of nesting and granularity. In this paper we first describe an event-aware model (the ABC model) which is capable of modeling and yet clearly differentiating between all of these, often recursive and overlapping events. We then illustrate how this model can be used as the foundation to facilitate semantic interoperability between MPEG-7 and MPEG-21. By expressing the semantics of both MPEG-7 and MPEG-21 metadata terms in RDF Schema (and some DAML+OIL extensions) and attaching the MPEG-7 and MPEG-21 class and property hierarchies to the appropriate top-level classes and properties of the ABC model, we are essentially able to define a single distributed machine-understandable ontology, which will enable interoperability of data and services across the entire multimedia content delivery chain.
