On Universality in Real Computation

Models of computation operating over the real numbers and computing a larger class of functions compared to the class of general recursive functions invariably introduce a non-finite element of infinite information encoded in an arbitrary non-computable number or non-recursive function. In this paper we show that Turing universality is only possible at every Turing degree but not over all, in that sense universality at the first level is elegantly well defined while universality at higher degrees is at least ambiguous. We propose a concept of universal relativity and universal jump between levels in the arithmetical and analytical hierarchy.
