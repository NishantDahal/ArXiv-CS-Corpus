Entropy functions and determinant inequalities

In this paper, we show that the characterisation of all determinant inequalities for $n \times n$ positive definite matrices is equivalent to determining the smallest closed and convex cone containing all entropy functions induced by $n$ scalar Gaussian random variables. We have obtained inner and outer bounds on the cone by using representable functions and entropic functions. In particular, these bounds are tight and explicit for $n \le 3$, implying that determinant inequalities for $3 \times 3$ positive definite matrices are completely characterized by Shannon-type information inequalities.
