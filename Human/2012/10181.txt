Characterizing Multivariate Information Flows

One of the crucial steps in scientific studies is to specify dependent relationships among factors in a system of interest. Given little knowledge of a system, can we characterize the underlying dependent relationships through observation of its temporal behaviors? In multivariate systems, there are potentially many possible dependent structures confusable with each other, and it may cause false detection of illusory dependency between unrelated factors. The present study proposes a new information-theoretic measure with consideration to such potential multivariate relationships. The proposed measure, called multivariate transfer entropy, is an extension of transfer entropy, a measure of temporal predictability. In the simulations and empirical studies, we demonstrated that the proposed measure characterized the latent dependent relationships in unknown dynamical systems more accurately than its alternative measure.
