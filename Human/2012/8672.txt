Kinects and Human Kinetics: A New Approach for Studying Crowd Behavior

Modeling crowd behavior relies on accurate data of pedestrian movements at a high level of detail. Imaging sensors such as cameras provide a good basis for capturing such detailed pedestrian motion data. However, currently available computer vision technologies, when applied to conventional video footage, still cannot automatically unveil accurate motions of groups of people or crowds from the image sequences. We present a novel data collection approach for studying crowd behavior which uses the increasingly popular low-cost sensor Microsoft Kinect. The Kinect captures both standard camera data and a three-dimensional depth map. Our human detection and tracking algorithm is based on agglomerative clustering of depth data captured from an elevated view - in contrast to the lateral view used for gesture recognition in Kinect gaming applications. Our approach transforms local Kinect 3D data to a common world coordinate system in order to stitch together human trajectories from multiple Kinects, which allows for a scalable and flexible capturing area. At a testbed with real-world pedestrian traffic we demonstrate that our approach can provide accurate trajectories from three Kinects with a Pedestrian Detection Rate of up to 94% and a Multiple Object Tracking Precision of 4 cm. Using a comprehensive dataset of 2240 captured human trajectories we calibrate three variations of the Social Force model. The results of our model validations indicate their particular ability to reproduce the observed crowd behavior in microscopic simulations.
