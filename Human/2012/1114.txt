Non-parametric convolution based image-segmentation of ill-posed objects applying context window approach

Context-dependence in human cognition process is a well-established fact. Following this, we introduced the image segmentation method that can use context to classify a pixel on the basis of its membership to a particular object-class of the concerned image. In the broad methodological steps, each pixel was defined by its context window (CW) surrounding it the size of which was fixed heuristically. CW texture defined by the intensities of its pixels was convoluted with weights optimized through a non-parametric function supported by a backpropagation network. Result of convolution was used to classify them. The training data points (i.e., pixels) were carefully chosen to include all variety of contexts of types, i) points within the object, ii) points near the edge but inside the objects, iii) points at the border of the objects, iv) points near the edge but outside the objects, v) points near or at the edge of the image frame. Moreover the training data points were selected from all the images within image-dataset. CW texture information for 1000 pixels from face area and background area of images were captured, out of which 700 CWs were used as training input data, and remaining 300 for testing. Our work gives the first time foundation of quantitative enumeration of efficiency of image-segmentation which is extendable to segment out more than 2 objects within an image.
