Distributed computing of Seismic Imaging Algorithms

The primary use of technical computing in the oil and gas industries is for seismic imaging of the earth's subsurface, driven by the business need for making well-informed drilling decisions during petroleum exploration and production. Since each oil/gas well in exploration areas costs several tens of millions of dollars, producing high-quality seismic images in a reasonable time can significantly reduce the risk of drilling a "dry hole". Similarly, these images are important as they can improve the position of wells in a billion-dollar producing oil field. However seismic imaging is very data- and compute-intensive which needs to process terabytes of data and require Gflop-years of computation (using "flop" to mean floating point operation per second). Due to the data/computing intensive nature of seismic imaging, parallel computing are used to process data to reduce the time compilation.
  With introducing of Cloud computing, MapReduce programming model has been attracted a lot of attention in parallel and distributed systems [1, 2] to execute massive processing algorithms such as Bioinformatics[3], Astronomy[4], Geology[5] and so on. In this report, we will investigate and discuss current approaches to fit seismic algorithms to MapReduce programming model.
