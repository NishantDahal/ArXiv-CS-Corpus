Improving Performance of Speaker Identification System Using Complementary Information Fusion

Feature extraction plays an important role as a front-end processing block in speaker identification (SI) process. Most of the SI systems utilize like Mel-Frequency Cepstral Coefficients (MFCC), Perceptual Linear Prediction (PLP), Linear Predictive Cepstral Coefficients (LPCC), as a feature for representing speech signal. Their derivations are based on short term processing of speech signal and they try to capture the vocal tract information ignoring the contribution from the vocal cord. Vocal cord cues are equally important in SI context, as the information like pitch frequency, phase in the residual signal, etc could convey important speaker specific attributes and are complementary to the information contained in spectral feature sets. In this paper we propose a novel feature set extracted from the residual signal of LP modeling. Higher-order statistical moments are used here to find the nonlinear relationship in residual signal. To get the advantages of complementarity vocal cord based decision score is fused with the vocal tract based score. The experimental results on two public databases show that fused mode system outperforms single spectral features.
